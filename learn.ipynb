{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/60], Loss: 4.9299\n",
      "Epoch [10/60], Loss: 2.1247\n",
      "Epoch [15/60], Loss: 0.9882\n",
      "Epoch [20/60], Loss: 0.5277\n",
      "Epoch [25/60], Loss: 0.3411\n",
      "Epoch [30/60], Loss: 0.2655\n",
      "Epoch [35/60], Loss: 0.2347\n",
      "Epoch [40/60], Loss: 0.2222\n",
      "Epoch [45/60], Loss: 0.2171\n",
      "Epoch [50/60], Loss: 0.2149\n",
      "Epoch [55/60], Loss: 0.2140\n",
      "Epoch [60/60], Loss: 0.2135\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    targets = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()  \n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkSSkcBcRSUIKdxGRJPT/AUix6l2JVzIZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ca24cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='../data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='../data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [100/600], Loss: 2.1971\n",
      "Epoch: [1/5], Step: [200/600], Loss: 2.0845\n",
      "Epoch: [1/5], Step: [300/600], Loss: 2.0577\n",
      "Epoch: [1/5], Step: [400/600], Loss: 1.9803\n",
      "Epoch: [1/5], Step: [500/600], Loss: 1.8951\n",
      "Epoch: [1/5], Step: [600/600], Loss: 1.7557\n",
      "Epoch: [2/5], Step: [100/600], Loss: 1.7800\n",
      "Epoch: [2/5], Step: [200/600], Loss: 1.6423\n",
      "Epoch: [2/5], Step: [300/600], Loss: 1.6390\n",
      "Epoch: [2/5], Step: [400/600], Loss: 1.5582\n",
      "Epoch: [2/5], Step: [500/600], Loss: 1.5641\n",
      "Epoch: [2/5], Step: [600/600], Loss: 1.4426\n",
      "Epoch: [3/5], Step: [100/600], Loss: 1.4284\n",
      "Epoch: [3/5], Step: [200/600], Loss: 1.3471\n",
      "Epoch: [3/5], Step: [300/600], Loss: 1.3260\n",
      "Epoch: [3/5], Step: [400/600], Loss: 1.3668\n",
      "Epoch: [3/5], Step: [500/600], Loss: 1.2721\n",
      "Epoch: [3/5], Step: [600/600], Loss: 1.3012\n",
      "Epoch: [4/5], Step: [100/600], Loss: 1.1877\n",
      "Epoch: [4/5], Step: [200/600], Loss: 1.0875\n",
      "Epoch: [4/5], Step: [300/600], Loss: 1.2097\n",
      "Epoch: [4/5], Step: [400/600], Loss: 1.1151\n",
      "Epoch: [4/5], Step: [500/600], Loss: 1.0962\n",
      "Epoch: [4/5], Step: [600/600], Loss: 1.0404\n",
      "Epoch: [5/5], Step: [100/600], Loss: 0.9351\n",
      "Epoch: [5/5], Step: [200/600], Loss: 1.1062\n",
      "Epoch: [5/5], Step: [300/600], Loss: 1.1214\n",
      "Epoch: [5/5], Step: [400/600], Loss: 0.9551\n",
      "Epoch: [5/5], Step: [500/600], Loss: 1.1407\n",
      "Epoch: [5/5], Step: [600/600], Loss: 1.0021\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset \n",
    "train_dataset = dsets.MNIST(root='../data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='../data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Model (1 hidden layer)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2983\n",
      "Epoch [1/5], Step [200/600], Loss: 0.4855\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2400\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1754\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1798\n",
      "Epoch [1/5], Step [600/600], Loss: 0.2138\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0722\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1377\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0720\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1191\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0996\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0550\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0485\n",
      "Epoch [3/5], Step [200/600], Loss: 0.1127\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0264\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0451\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0449\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0612\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0927\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0198\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0267\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0781\n",
      "Epoch [4/5], Step [500/600], Loss: 0.1144\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0676\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0510\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0664\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0437\n",
      "Epoch [5/5], Step [400/600], Loss: 0.1134\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0451\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0710\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Convert torch tensor to Variable\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='../data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='../data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CNN Model (2 conv layer)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cnn = CNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/600] Loss: 0.2739\n",
      "Epoch [1/5], Iter [200/600] Loss: 0.1497\n",
      "Epoch [1/5], Iter [300/600] Loss: 0.0468\n",
      "Epoch [1/5], Iter [400/600] Loss: 0.0679\n",
      "Epoch [1/5], Iter [500/600] Loss: 0.0619\n",
      "Epoch [1/5], Iter [600/600] Loss: 0.0707\n",
      "Epoch [2/5], Iter [100/600] Loss: 0.0603\n",
      "Epoch [2/5], Iter [200/600] Loss: 0.0632\n",
      "Epoch [2/5], Iter [300/600] Loss: 0.0086\n",
      "Epoch [2/5], Iter [400/600] Loss: 0.0283\n",
      "Epoch [2/5], Iter [500/600] Loss: 0.1828\n",
      "Epoch [2/5], Iter [600/600] Loss: 0.0286\n",
      "Epoch [3/5], Iter [100/600] Loss: 0.0642\n",
      "Epoch [3/5], Iter [200/600] Loss: 0.0358\n",
      "Epoch [3/5], Iter [300/600] Loss: 0.0321\n",
      "Epoch [3/5], Iter [400/600] Loss: 0.0054\n",
      "Epoch [3/5], Iter [500/600] Loss: 0.0393\n",
      "Epoch [3/5], Iter [600/600] Loss: 0.0314\n",
      "Epoch [4/5], Iter [100/600] Loss: 0.0313\n",
      "Epoch [4/5], Iter [200/600] Loss: 0.0452\n",
      "Epoch [4/5], Iter [300/600] Loss: 0.0291\n",
      "Epoch [4/5], Iter [400/600] Loss: 0.0153\n",
      "Epoch [4/5], Iter [500/600] Loss: 0.0572\n",
      "Epoch [4/5], Iter [600/600] Loss: 0.0362\n",
      "Epoch [5/5], Iter [100/600] Loss: 0.0037\n",
      "Epoch [5/5], Iter [200/600] Loss: 0.0297\n",
      "Epoch [5/5], Iter [300/600] Loss: 0.0076\n",
      "Epoch [5/5], Iter [400/600] Loss: 0.0158\n",
      "Epoch [5/5], Iter [500/600] Loss: 0.0432\n",
      "Epoch [5/5], Iter [600/600] Loss: 0.0064\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 99 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implementation of https://arxiv.org/pdf/1512.03385.pdf.\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Image Preprocessing \n",
    "transform = transforms.Compose([\n",
    "    transforms.Scale(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n",
      "Extracting tar file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 Dataset\n",
    "train_dataset = dsets.CIFAR10(root='../data/',\n",
    "                               train=True, \n",
    "                               transform=transform,\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = dsets.CIFAR10(root='../data/',\n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 3x3 Convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ResNet Module\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[0], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "resnet = ResNet(ResidualBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Iter [100/500] Loss: 0.7085\n",
      "Epoch [1/25], Iter [200/500] Loss: 0.4810\n",
      "Epoch [1/25], Iter [300/500] Loss: 0.6156\n",
      "Epoch [1/25], Iter [400/500] Loss: 0.5820\n",
      "Epoch [1/25], Iter [500/500] Loss: 0.7056\n",
      "Epoch [2/25], Iter [100/500] Loss: 0.6976\n",
      "Epoch [2/25], Iter [200/500] Loss: 0.7040\n",
      "Epoch [2/25], Iter [300/500] Loss: 0.6183\n",
      "Epoch [2/25], Iter [400/500] Loss: 0.6477\n",
      "Epoch [2/25], Iter [500/500] Loss: 0.6478\n",
      "Epoch [3/25], Iter [100/500] Loss: 0.4870\n",
      "Epoch [3/25], Iter [200/500] Loss: 0.6026\n",
      "Epoch [3/25], Iter [300/500] Loss: 0.7608\n",
      "Epoch [3/25], Iter [400/500] Loss: 0.6777\n",
      "Epoch [3/25], Iter [500/500] Loss: 0.6317\n",
      "Epoch [4/25], Iter [100/500] Loss: 0.7225\n",
      "Epoch [4/25], Iter [200/500] Loss: 0.9548\n",
      "Epoch [4/25], Iter [300/500] Loss: 0.4294\n",
      "Epoch [4/25], Iter [400/500] Loss: 0.5718\n",
      "Epoch [4/25], Iter [500/500] Loss: 0.5480\n",
      "Epoch [5/25], Iter [100/500] Loss: 0.6798\n",
      "Epoch [5/25], Iter [200/500] Loss: 0.5859\n",
      "Epoch [5/25], Iter [300/500] Loss: 0.6270\n",
      "Epoch [5/25], Iter [400/500] Loss: 0.6685\n",
      "Epoch [5/25], Iter [500/500] Loss: 0.4392\n",
      "Epoch [6/25], Iter [100/500] Loss: 0.4743\n",
      "Epoch [6/25], Iter [200/500] Loss: 0.4751\n",
      "Epoch [6/25], Iter [300/500] Loss: 0.4188\n",
      "Epoch [6/25], Iter [400/500] Loss: 0.5591\n",
      "Epoch [6/25], Iter [500/500] Loss: 0.3730\n",
      "Epoch [7/25], Iter [100/500] Loss: 0.5071\n",
      "Epoch [7/25], Iter [200/500] Loss: 0.4793\n",
      "Epoch [7/25], Iter [300/500] Loss: 0.5042\n",
      "Epoch [7/25], Iter [400/500] Loss: 0.4402\n",
      "Epoch [7/25], Iter [500/500] Loss: 0.4025\n",
      "Epoch [8/25], Iter [100/500] Loss: 0.3256\n",
      "Epoch [8/25], Iter [200/500] Loss: 0.2970\n",
      "Epoch [8/25], Iter [300/500] Loss: 0.5524\n",
      "Epoch [8/25], Iter [400/500] Loss: 0.5430\n",
      "Epoch [8/25], Iter [500/500] Loss: 0.4139\n",
      "Epoch [9/25], Iter [100/500] Loss: 0.4878\n",
      "Epoch [9/25], Iter [200/500] Loss: 0.4113\n",
      "Epoch [9/25], Iter [300/500] Loss: 0.4568\n",
      "Epoch [9/25], Iter [400/500] Loss: 0.4114\n",
      "Epoch [9/25], Iter [500/500] Loss: 0.4408\n",
      "Epoch [10/25], Iter [100/500] Loss: 0.3540\n",
      "Epoch [10/25], Iter [200/500] Loss: 0.3459\n",
      "Epoch [10/25], Iter [300/500] Loss: 0.5096\n",
      "Epoch [10/25], Iter [400/500] Loss: 0.3690\n",
      "Epoch [10/25], Iter [500/500] Loss: 0.4499\n",
      "Epoch [11/25], Iter [100/500] Loss: 0.3176\n",
      "Epoch [11/25], Iter [200/500] Loss: 0.4898\n",
      "Epoch [11/25], Iter [300/500] Loss: 0.4162\n",
      "Epoch [11/25], Iter [400/500] Loss: 0.3451\n",
      "Epoch [11/25], Iter [500/500] Loss: 0.3638\n",
      "Epoch [12/25], Iter [100/500] Loss: 0.4247\n",
      "Epoch [12/25], Iter [200/500] Loss: 0.4085\n",
      "Epoch [12/25], Iter [300/500] Loss: 0.3145\n",
      "Epoch [12/25], Iter [400/500] Loss: 0.3131\n",
      "Epoch [12/25], Iter [500/500] Loss: 0.3984\n",
      "Epoch [13/25], Iter [100/500] Loss: 0.3762\n",
      "Epoch [13/25], Iter [200/500] Loss: 0.5963\n",
      "Epoch [13/25], Iter [300/500] Loss: 0.6903\n",
      "Epoch [13/25], Iter [400/500] Loss: 0.3494\n",
      "Epoch [13/25], Iter [500/500] Loss: 0.2521\n",
      "Epoch [14/25], Iter [100/500] Loss: 0.3428\n",
      "Epoch [14/25], Iter [200/500] Loss: 0.4183\n",
      "Epoch [14/25], Iter [300/500] Loss: 0.3598\n",
      "Epoch [14/25], Iter [400/500] Loss: 0.4023\n",
      "Epoch [14/25], Iter [500/500] Loss: 0.3850\n",
      "Epoch [15/25], Iter [100/500] Loss: 0.5746\n",
      "Epoch [15/25], Iter [200/500] Loss: 0.3936\n",
      "Epoch [15/25], Iter [300/500] Loss: 0.3877\n",
      "Epoch [15/25], Iter [400/500] Loss: 0.3914\n",
      "Epoch [15/25], Iter [500/500] Loss: 0.3447\n",
      "Epoch [16/25], Iter [100/500] Loss: 0.4627\n",
      "Epoch [16/25], Iter [200/500] Loss: 0.3160\n",
      "Epoch [16/25], Iter [300/500] Loss: 0.3918\n",
      "Epoch [16/25], Iter [400/500] Loss: 0.4041\n",
      "Epoch [16/25], Iter [500/500] Loss: 0.2031\n",
      "Epoch [17/25], Iter [100/500] Loss: 0.3521\n",
      "Epoch [17/25], Iter [200/500] Loss: 0.4630\n",
      "Epoch [17/25], Iter [300/500] Loss: 0.2464\n",
      "Epoch [17/25], Iter [400/500] Loss: 0.3346\n",
      "Epoch [17/25], Iter [500/500] Loss: 0.2593\n",
      "Epoch [18/25], Iter [100/500] Loss: 0.2915\n",
      "Epoch [18/25], Iter [200/500] Loss: 0.5358\n",
      "Epoch [18/25], Iter [300/500] Loss: 0.4247\n",
      "Epoch [18/25], Iter [400/500] Loss: 0.4351\n",
      "Epoch [18/25], Iter [500/500] Loss: 0.2964\n",
      "Epoch [19/25], Iter [100/500] Loss: 0.2822\n",
      "Epoch [19/25], Iter [200/500] Loss: 0.4567\n",
      "Epoch [19/25], Iter [300/500] Loss: 0.3773\n",
      "Epoch [19/25], Iter [400/500] Loss: 0.4482\n",
      "Epoch [19/25], Iter [500/500] Loss: 0.3105\n",
      "Epoch [20/25], Iter [100/500] Loss: 0.2645\n",
      "Epoch [20/25], Iter [200/500] Loss: 0.4355\n",
      "Epoch [20/25], Iter [300/500] Loss: 0.2788\n",
      "Epoch [20/25], Iter [400/500] Loss: 0.2229\n",
      "Epoch [20/25], Iter [500/500] Loss: 0.3833\n",
      "Epoch [21/25], Iter [100/500] Loss: 0.3214\n",
      "Epoch [21/25], Iter [200/500] Loss: 0.4895\n",
      "Epoch [21/25], Iter [300/500] Loss: 0.3694\n",
      "Epoch [21/25], Iter [400/500] Loss: 0.4031\n",
      "Epoch [21/25], Iter [500/500] Loss: 0.3038\n",
      "Epoch [22/25], Iter [100/500] Loss: 0.3830\n",
      "Epoch [22/25], Iter [200/500] Loss: 0.2655\n",
      "Epoch [22/25], Iter [300/500] Loss: 0.3437\n",
      "Epoch [22/25], Iter [400/500] Loss: 0.2748\n",
      "Epoch [22/25], Iter [500/500] Loss: 0.3778\n",
      "Epoch [23/25], Iter [100/500] Loss: 0.2762\n",
      "Epoch [23/25], Iter [200/500] Loss: 0.3874\n",
      "Epoch [23/25], Iter [300/500] Loss: 0.3793\n",
      "Epoch [23/25], Iter [400/500] Loss: 0.4827\n",
      "Epoch [23/25], Iter [500/500] Loss: 0.2808\n",
      "Epoch [24/25], Iter [100/500] Loss: 0.2771\n",
      "Epoch [24/25], Iter [200/500] Loss: 0.4203\n",
      "Epoch [24/25], Iter [300/500] Loss: 0.3053\n",
      "Epoch [24/25], Iter [400/500] Loss: 0.3646\n",
      "Epoch [24/25], Iter [500/500] Loss: 0.3645\n",
      "Epoch [25/25], Iter [100/500] Loss: 0.2783\n",
      "Epoch [25/25], Iter [200/500] Loss: 0.3089\n",
      "Epoch [25/25], Iter [300/500] Loss: 0.3906\n",
      "Epoch [25/25], Iter [400/500] Loss: 0.2758\n",
      "Epoch [25/25], Iter [500/500] Loss: 0.3557\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "for epoch in range(25):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch [%d/%d], Iter [%d/%d] Loss: %.4f\" %(epoch+1, 25, i+1, 500, loss.data[0]))\n",
    "\n",
    "    # Decaying Learning Rate\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        lr /= 3\n",
    "        optimizer = torch.optim.Adam(resnet.parameters(), lr=lr) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images)\n",
    "    outputs = resnet(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the model on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='../data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='../data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rnn = RNN(input_size, hidden_size, num_layers, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.5438\n",
      "Epoch [1/2], Step [200/600], Loss: 0.3616\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1673\n",
      "Epoch [1/2], Step [400/600], Loss: 0.3234\n",
      "Epoch [1/2], Step [500/600], Loss: 0.0999\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1208\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1724\n",
      "Epoch [2/2], Step [200/600], Loss: 0.2256\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1278\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1103\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1295\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1743\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, sequence_length, input_size))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, sequence_length, input_size))\n",
    "    outputs = rnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    \n",
    "class Corpus(object):\n",
    "    def __init__(self, path='./data'):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = os.path.join(path, 'train.txt')\n",
    "        self.test = os.path.join(path, 'test.txt')\n",
    "\n",
    "    def get_data(self, path, batch_size=20):\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words: \n",
    "                    self.dictionary.add_word(word)  \n",
    "        \n",
    "        # Tokenize the file content\n",
    "        ids = torch.LongTensor(tokens)\n",
    "        token = 0\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx[word]\n",
    "                    token += 1\n",
    "        num_batches = ids.size(0) // batch_size\n",
    "        ids = ids[:num_batches*batch_size]\n",
    "        return ids.view(batch_size, -1)\n",
    "    \n",
    "# RNN Based Language Model\n",
    "class RNNLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(RNNLM, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        self.embed.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "        self.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        # Embed word ids to vectors\n",
    "        x = self.embed(x) \n",
    "        \n",
    "        # Forward propagate RNN  \n",
    "        out, h = self.lstm(x, h)\n",
    "        \n",
    "        # Reshape output to (batch_size*sequence_length, hidden_size)\n",
    "        out = out.contiguous().view(out.size(0)*out.size(1), out.size(2))\n",
    "        \n",
    "        # Decode hidden states of all time step\n",
    "        out = self.linear(out)  \n",
    "        return out, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "embed_size = 128\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "num_epochs = 5\n",
    "num_samples = 1000   # number of words to be sampled\n",
    "batch_size = 20\n",
    "seq_length = 30\n",
    "learning_rate = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Penn Treebank Dataset\n",
    "train_path = './data/train.txt'\n",
    "sample_path = './sample.txt'\n",
    "corpus = Corpus()\n",
    "ids = corpus.get_data(train_path, batch_size)\n",
    "vocab_size = len(corpus.dictionary)\n",
    "num_batches = ids.size(1) // seq_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RNNLM(vocab_size, embed_size, hidden_size, num_layers)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Truncated Backpropagation \n",
    "def detach(states):\n",
    "    return [Variable(state.data) for state in states] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step[0/1549], Loss: 9.212, Perplexity: 10012.28\n",
      "Epoch [1/5], Step[100/1549], Loss: 6.026, Perplexity: 414.23\n",
      "Epoch [1/5], Step[200/1549], Loss: 5.932, Perplexity: 376.74\n",
      "Epoch [1/5], Step[300/1549], Loss: 5.804, Perplexity: 331.55\n",
      "Epoch [1/5], Step[400/1549], Loss: 5.696, Perplexity: 297.77\n",
      "Epoch [1/5], Step[500/1549], Loss: 5.142, Perplexity: 171.08\n",
      "Epoch [1/5], Step[600/1549], Loss: 5.206, Perplexity: 182.31\n",
      "Epoch [1/5], Step[700/1549], Loss: 5.402, Perplexity: 221.81\n",
      "Epoch [1/5], Step[800/1549], Loss: 5.212, Perplexity: 183.39\n",
      "Epoch [1/5], Step[900/1549], Loss: 5.108, Perplexity: 165.26\n",
      "Epoch [1/5], Step[1000/1549], Loss: 5.165, Perplexity: 174.96\n",
      "Epoch [1/5], Step[1100/1549], Loss: 5.335, Perplexity: 207.46\n",
      "Epoch [1/5], Step[1200/1549], Loss: 5.166, Perplexity: 175.21\n",
      "Epoch [1/5], Step[1300/1549], Loss: 5.094, Perplexity: 163.09\n",
      "Epoch [1/5], Step[1400/1549], Loss: 4.825, Perplexity: 124.56\n",
      "Epoch [1/5], Step[1500/1549], Loss: 5.181, Perplexity: 177.91\n",
      "Epoch [2/5], Step[0/1549], Loss: 5.499, Perplexity: 244.40\n",
      "Epoch [2/5], Step[100/1549], Loss: 4.677, Perplexity: 107.47\n",
      "Epoch [2/5], Step[200/1549], Loss: 4.745, Perplexity: 115.01\n",
      "Epoch [2/5], Step[300/1549], Loss: 4.867, Perplexity: 129.97\n",
      "Epoch [2/5], Step[400/1549], Loss: 4.733, Perplexity: 113.58\n",
      "Epoch [2/5], Step[500/1549], Loss: 4.242, Perplexity: 69.52\n",
      "Epoch [2/5], Step[600/1549], Loss: 4.556, Perplexity: 95.23\n",
      "Epoch [2/5], Step[700/1549], Loss: 4.592, Perplexity: 98.67\n",
      "Epoch [2/5], Step[800/1549], Loss: 4.538, Perplexity: 93.53\n",
      "Epoch [2/5], Step[900/1549], Loss: 4.439, Perplexity: 84.68\n",
      "Epoch [2/5], Step[1000/1549], Loss: 4.473, Perplexity: 87.60\n",
      "Epoch [2/5], Step[1100/1549], Loss: 4.731, Perplexity: 113.41\n",
      "Epoch [2/5], Step[1200/1549], Loss: 4.598, Perplexity: 99.27\n",
      "Epoch [2/5], Step[1300/1549], Loss: 4.428, Perplexity: 83.73\n",
      "Epoch [2/5], Step[1400/1549], Loss: 4.120, Perplexity: 61.56\n",
      "Epoch [2/5], Step[1500/1549], Loss: 4.476, Perplexity: 87.88\n",
      "Epoch [3/5], Step[0/1549], Loss: 4.807, Perplexity: 122.42\n",
      "Epoch [3/5], Step[100/1549], Loss: 4.076, Perplexity: 58.88\n",
      "Epoch [3/5], Step[200/1549], Loss: 4.187, Perplexity: 65.81\n",
      "Epoch [3/5], Step[300/1549], Loss: 4.196, Perplexity: 66.41\n",
      "Epoch [3/5], Step[400/1549], Loss: 4.096, Perplexity: 60.11\n",
      "Epoch [3/5], Step[500/1549], Loss: 3.688, Perplexity: 39.97\n",
      "Epoch [3/5], Step[600/1549], Loss: 4.085, Perplexity: 59.44\n",
      "Epoch [3/5], Step[700/1549], Loss: 4.015, Perplexity: 55.40\n",
      "Epoch [3/5], Step[800/1549], Loss: 4.024, Perplexity: 55.91\n",
      "Epoch [3/5], Step[900/1549], Loss: 3.834, Perplexity: 46.22\n",
      "Epoch [3/5], Step[1000/1549], Loss: 3.944, Perplexity: 51.63\n",
      "Epoch [3/5], Step[1100/1549], Loss: 4.185, Perplexity: 65.72\n",
      "Epoch [3/5], Step[1200/1549], Loss: 4.083, Perplexity: 59.30\n",
      "Epoch [3/5], Step[1300/1549], Loss: 3.829, Perplexity: 46.02\n",
      "Epoch [3/5], Step[1400/1549], Loss: 3.555, Perplexity: 35.00\n",
      "Epoch [3/5], Step[1500/1549], Loss: 3.865, Perplexity: 47.69\n",
      "Epoch [4/5], Step[0/1549], Loss: 4.122, Perplexity: 61.70\n",
      "Epoch [4/5], Step[100/1549], Loss: 3.587, Perplexity: 36.12\n",
      "Epoch [4/5], Step[200/1549], Loss: 3.753, Perplexity: 42.65\n",
      "Epoch [4/5], Step[300/1549], Loss: 3.748, Perplexity: 42.42\n",
      "Epoch [4/5], Step[400/1549], Loss: 3.622, Perplexity: 37.40\n",
      "Epoch [4/5], Step[500/1549], Loss: 3.247, Perplexity: 25.71\n",
      "Epoch [4/5], Step[600/1549], Loss: 3.701, Perplexity: 40.49\n",
      "Epoch [4/5], Step[700/1549], Loss: 3.567, Perplexity: 35.40\n",
      "Epoch [4/5], Step[800/1549], Loss: 3.623, Perplexity: 37.44\n",
      "Epoch [4/5], Step[900/1549], Loss: 3.309, Perplexity: 27.36\n",
      "Epoch [4/5], Step[1000/1549], Loss: 3.443, Perplexity: 31.28\n",
      "Epoch [4/5], Step[1100/1549], Loss: 3.693, Perplexity: 40.16\n",
      "Epoch [4/5], Step[1200/1549], Loss: 3.550, Perplexity: 34.82\n",
      "Epoch [4/5], Step[1300/1549], Loss: 3.357, Perplexity: 28.71\n",
      "Epoch [4/5], Step[1400/1549], Loss: 3.034, Perplexity: 20.78\n",
      "Epoch [4/5], Step[1500/1549], Loss: 3.437, Perplexity: 31.10\n",
      "Epoch [5/5], Step[0/1549], Loss: 3.606, Perplexity: 36.83\n",
      "Epoch [5/5], Step[100/1549], Loss: 3.218, Perplexity: 24.97\n",
      "Epoch [5/5], Step[200/1549], Loss: 3.296, Perplexity: 27.00\n",
      "Epoch [5/5], Step[300/1549], Loss: 3.320, Perplexity: 27.67\n",
      "Epoch [5/5], Step[400/1549], Loss: 3.336, Perplexity: 28.11\n",
      "Epoch [5/5], Step[500/1549], Loss: 2.929, Perplexity: 18.70\n",
      "Epoch [5/5], Step[600/1549], Loss: 3.399, Perplexity: 29.93\n",
      "Epoch [5/5], Step[700/1549], Loss: 3.214, Perplexity: 24.87\n",
      "Epoch [5/5], Step[800/1549], Loss: 3.265, Perplexity: 26.18\n",
      "Epoch [5/5], Step[900/1549], Loss: 3.012, Perplexity: 20.33\n",
      "Epoch [5/5], Step[1000/1549], Loss: 3.139, Perplexity: 23.09\n",
      "Epoch [5/5], Step[1100/1549], Loss: 3.315, Perplexity: 27.51\n",
      "Epoch [5/5], Step[1200/1549], Loss: 3.285, Perplexity: 26.71\n",
      "Epoch [5/5], Step[1300/1549], Loss: 3.069, Perplexity: 21.51\n",
      "Epoch [5/5], Step[1400/1549], Loss: 2.705, Perplexity: 14.96\n",
      "Epoch [5/5], Step[1500/1549], Loss: 3.118, Perplexity: 22.60\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    # Initial hidden and memory states\n",
    "    states = (Variable(torch.zeros(num_layers, batch_size, hidden_size)),\n",
    "              Variable(torch.zeros(num_layers, batch_size, hidden_size)))\n",
    "    \n",
    "    for i in range(0, ids.size(1) - seq_length, seq_length):\n",
    "        # Get batch inputs and targets\n",
    "        inputs = Variable(ids[:, i:i+seq_length])\n",
    "        targets = Variable(ids[:, (i+1):(i+1)+seq_length].contiguous())\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        model.zero_grad()\n",
    "        states = detach(states)\n",
    "        outputs, states = model(inputs, states) \n",
    "        loss = criterion(outputs, targets.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        step = (i+1) // seq_length\n",
    "        if step % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step[%d/%d], Loss: %.3f, Perplexity: %5.2f' %\n",
    "                   (epoch+1, num_epochs, step, num_batches, loss.data[0], np.exp(loss.data[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version <unk> who jones chairman dennis <unk> r. utah in a position in N after he was a <unk> \n",
      "most former chairmen had <unk> been called <unk> for N most years ago at the agency and its <unk> texas energy operation \n",
      "so far crunch can close to de new job and also <unk> their own wives \n",
      "it can even maintain its music above it \n",
      "<unk> is the crown prince and <unk> operation supermarket & <unk> \n",
      "common <unk> prosecutors featured a $ <unk> a <unk> <unk> <unk> to a design when a treatment made a stronger debate toward <unk> <unk> in N \n",
      "for everyone frightened it was to leave it clear even \n",
      "i would n't find who readers are going into all scenes going off or even never yet to be abc or <unk> to baltimore \n",
      "eventually they <unk> he says \n",
      "though it continues to convey that schedules into the basic system still <unk> protein to post which were one of many <unk> students expectations and federal <unk> salaries after the third game after the time \n",
      "the league is to draw someone again when you will buy \n",
      "or eight season left the winner \n",
      "besides resources the <unk> has held a loss of $ N or almost tell cbs news \n",
      "meanwhile as in N it seemed to be will share the scenes without certain this for the ninth to $ N a share \n",
      "the chairman real estate of the sponsors said <unk> by a <unk> <unk> institution became a <unk> of employee business magazine <unk> <unk> a <unk> mass. <unk> ranges from a boring <unk> and N sports <unk> at a <unk> news conference call apples their productions \n",
      "ad was n't fully cut mr. jones 's successor says \n",
      "these days <unk> <unk> consider a <unk> note that was on an shop magazine \n",
      "the novel is the most four key to mr. roman is a black appreciation \n",
      "mr. wood says and his latest has a commercial bank on the project \n",
      "with the heart news ogilvy that <unk> the navy broadcast with a <unk> post that makes <unk> in texas and a tough east germany which is several cbs networks \n",
      "mr. <unk> 's ogilvy could succeed arthur l. \n",
      "jerry brown \n",
      "keeping the giants giants spend $ N million were on mr. <unk> <unk> a <unk> salesman & <unk> walking into the better than a year 's N <unk> \n",
      "<unk> <unk> was named to an lotus suitable telephone group mr. <unk> takes control \n",
      "a combined with a bank to settle the newly hired customers as chief executive \n",
      "ogilvy & mather has a top of them in N but was in such ventures as a blow and a rival of italian airlines a producer for the houston box firm of chicago-based connaught <unk> \n",
      "in the case sony will pay $ N in each case on an <unk> flow to about N executives of <unk> of california \n",
      "by contrast they have a hard way and that even less commercial and provide our presence the <unk> with what has to be made \n",
      "i 'm going to be selling for college until N N to manage quite voluntarily \n",
      "factory stadium has finally gotten active in minnesota \n",
      "this is another garden <unk> <unk> rocks stories about bonn 's nbc news stories about N rooms advertising \n",
      "they 're N N asbestos per in south and that from naturally great \n",
      "some former growers notably the mouse chapter may took the <unk> season \n",
      "the league is in <unk> that she was assistant of the baseball act on old <unk> and high scientists <unk> <unk> and a beer magazine <unk> \n",
      "mr. <unk> was a <unk> copies from several other three questions at the wine now on the <unk> projection \n",
      "<unk> interviewed afternoon and <unk> journalism went back to their <unk> \n",
      "but while most one <unk> off with a television news the first members of a new series of today took a city effort to communist european news at the <unk> museum troop to N people marched to N N the last season with the virus \n",
      "he 's recalls the team <unk> baseball altogether publicity became missing in his institute as collateral were n't just walking out \n",
      "although the manager made a nearly <unk> interesting party he 'd night \n",
      "he will definitely remember the new red \n",
      "ms. chung 's withdrawal is the nfl time \n",
      "i 'm not all man life we 'll be moved at another time their house says no surprise \n",
      "<unk> makes it bobby <unk> walking me as as a television definition \n",
      "instead posting it how rep. filters sells the <unk> for a <unk> post \n",
      "in the suit to its mother <unk> her husband <unk> johnson 's <unk> proposed series N affair abc news news for a <unk> owners contest about design sports camp actors off the sweat \n",
      "at a weather this magazine he <unk> first phillips to a <unk> court camp at cbs news around dean football fifth and <unk> both as bobby thomson was texas as the tire master \n",
      "and in the league he pledged to seem <unk> by news news news wires at the game manager president de <unk> <unk> news reports saying he were present \n",
      "<unk> m. jerry a <unk> student <unk> <unk> the <unk> dream of the longer and bobby thomson was a <unk> company well-known mr. <unk> at the university of puerto rico to fill his team struck \n",
      "N years old after it absorbed \n",
      "along with <unk> fiber when it was easy to <unk> that \n",
      "only after a giant exhibition the <unk> national jailed <unk> a huge blue <unk> in the hole immediately for <unk> the 1980s \n",
      "the <unk> black market <unk> me to express \n",
      "just cbs started into second the american express job mr. \n"
     ]
    }
   ],
   "source": [
    "# Sampling\n",
    "with open(sample_path, 'w') as f:\n",
    "    # Set intial hidden ane memory states\n",
    "    state = (Variable(torch.zeros(num_layers, 1, hidden_size)),\n",
    "         Variable(torch.zeros(num_layers, 1, hidden_size)))\n",
    "\n",
    "    # Select one word id randomly\n",
    "    prob = torch.ones(vocab_size)\n",
    "    input = Variable(torch.multinomial(prob, num_samples=1).unsqueeze(1),\n",
    "                     volatile=True)\n",
    "    s = \"\"\n",
    "    for i in range(num_samples):\n",
    "        # Forward propagate rnn \n",
    "        output, state = model(input, state)\n",
    "        \n",
    "        # Sample a word id\n",
    "        prob = output.squeeze().data.exp()\n",
    "        word_id = torch.multinomial(prob, 1)[0]\n",
    "        \n",
    "        # Feed sampled word id to next time step\n",
    "        input.data.fill_(word_id)\n",
    "        \n",
    "        # File write\n",
    "        word = corpus.dictionary.idx2word[word_id]\n",
    "        word = '\\n' if word == '<eos>' else word + ' '\n",
    "        s += word\n",
    "    print (s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
